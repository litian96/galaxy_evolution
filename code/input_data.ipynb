{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DIRECTORY = \"/mnt/ds3lab/litian/AE_BEGAN/data/galaxy_64/train\"  # use these real images to train a classifier\n",
    "\n",
    "RAW_IMAGE_HEIGHT = 64\n",
    "RAW_IMAGE_WIDTH = 64\n",
    "\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "all_images_num = 0\n",
    "\n",
    "def load_image_as_array(filepath):\n",
    "    \"\"\"\n",
    "    Loads a single image and returns it as an array\n",
    "    :param filepath: path to image file\n",
    "    :return: array of image with size IMAGE_WIDTH*IMAGE_HEIGHT*3\n",
    "    \"\"\"\n",
    "    #im = Image.open(filepath)\n",
    "    #print im.size\n",
    "    #im = im.resize((RAW_IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    #print im.size\n",
    "\n",
    "    im = mpimg.imread(filepath)\n",
    "    im = misc.imresize(im,(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH))\n",
    "    # till now. it is right\n",
    "    if len(np.shape(im)) is 2:\n",
    "        array = np.empty((RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH, 3), dtype=np.uint8)\n",
    "        array[:, :, :] = np.array(im)[:, :, np.newaxis]\n",
    "    else:\n",
    "        array = np.array(im)\n",
    "\n",
    "    return array.astype(np.float32)\n",
    "\n",
    "\n",
    "def create_one_hot_vector(index, length):\n",
    "    \"\"\"\n",
    "    Creates a one-hot vector with that specified length and a 1 at the specified index\n",
    "    :param index: index of 1 in vector\n",
    "    :param length: length of vector\n",
    "    :return: one-hot vector\n",
    "    \"\"\"\n",
    "    assert length > 0, \"One-hot vector length must be a positive number\"\n",
    "    assert 0 <= index < length, \"Index (%s) must be between 0 and length(%s)\" % (index, length)\n",
    "\n",
    "    vector = np.zeros(length)\n",
    "    vector[index] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "def load_all_images(class_ids, num_images):\n",
    "    num_classes = len(class_ids)\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    for index, class_id in enumerate(class_ids):\n",
    "        \n",
    "        class_path = os.path.join(IMAGE_DIRECTORY, class_id)\n",
    "        if os.path.isdir(class_path):\n",
    "            files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "            num_class_files = min(len(files), num_images) #\n",
    "            print num_class_files\n",
    "\t    #if num_class_files > 15:\n",
    "\t\t#num_class_files = 10\n",
    "            for n in range(0, num_class_files):\n",
    "                image = load_image_as_array(os.path.join(class_path, files[n]))\n",
    "                all_images.append(image)\n",
    "                all_labels.append(create_one_hot_vector(index, num_classes))\n",
    "    all_images_num = len(all_images)\n",
    "    print len(all_images)\n",
    "    return np.array(all_images), np.array(all_labels)\n",
    "\n",
    "def transform_images(images, randomize = False):\n",
    "    assert IMAGE_WIDTH <= RAW_IMAGE_WIDTH\n",
    "    assert IMAGE_HEIGHT <= RAW_IMAGE_HEIGHT\n",
    "\n",
    "    transformed = []\n",
    "\n",
    "    images = images.reshape(images.shape[0], RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH, 3)\n",
    "\n",
    "    for i in range(0, len(images)):\n",
    "        image = images[i]\n",
    "        if randomize:\n",
    "            left_padding = np.random.randint(0, RAW_IMAGE_WIDTH - IMAGE_WIDTH)\n",
    "            top_padding = np.random.randint(0, RAW_IMAGE_HEIGHT - IMAGE_HEIGHT)\n",
    "            cropped_image = image[top_padding:top_padding + IMAGE_HEIGHT, left_padding:left_padding + IMAGE_WIDTH]\n",
    "\n",
    "            if np.random.ranf() <= 0.5:\n",
    "                cropped_image = cropped_image[:, ::-1, :]\n",
    "        else:\n",
    "            left_padding = (RAW_IMAGE_WIDTH - IMAGE_WIDTH)/2\n",
    "            top_padding = (RAW_IMAGE_HEIGHT - IMAGE_HEIGHT)/2\n",
    "            cropped_image = image[top_padding:top_padding + IMAGE_HEIGHT, left_padding:left_padding + IMAGE_WIDTH]\n",
    "        transformed.append(cropped_image)\n",
    "\n",
    "    transformed = np.asarray(transformed)\n",
    "    return transformed.reshape(transformed.shape[0], IMAGE_HEIGHT*IMAGE_WIDTH, 3)\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, images, labels):\n",
    "        \"\"\"Construct a DataSet using the given images and labels\n",
    "        \"\"\"\n",
    "\n",
    "        assert images.shape[0] == labels.shape[0], (\n",
    "            'images.shape: %s labels.shape: %s' % (images.shape,\n",
    "                                                   labels.shape))\n",
    "        self._num_examples = images.shape[0]\n",
    "\n",
    "        assert images.shape[3] == 3\n",
    "        images = images.reshape(images.shape[0],\n",
    "                                images.shape[1] * images.shape[2], 3)\n",
    "\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size, random_crop=False):\n",
    "        assert batch_size <= self._num_examples\n",
    "\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "\n",
    "        end = self._index_in_epoch\n",
    "        raw_images = self._images[start:end]\n",
    "\n",
    "        return transform_images(raw_images, randomize=random_crop), self._labels[start:end]\n",
    "\n",
    "\n",
    "def create_datasets(class_ids, num_samples=10000, val_fraction=0.2, test_fraction=0.2):\n",
    "    #num_sample\n",
    "    \"\"\"\n",
    "    Creates training, validation, and test datasets from the given class ids using the desired proportions\n",
    "    :param class_ids: ImageNet class ids of all classes to include\n",
    "    :param num_samples: maximum sample images for each class\n",
    "    :param val_fraction: fraction of images to put into validation set\n",
    "    :param test_fraction: fraction of images to put into test set\n",
    "    :return: training_set, validation_set, test_dataset\n",
    "    \"\"\"\n",
    "\n",
    "    assert 0 <= val_fraction <= 0.25, \"Validation fraction %s must be between 0 and 0.25\" % val_fraction\n",
    "    assert 0 <= test_fraction <= 0.25, \"Test fraction %s must be between 0 and 0.25\" % test_fraction\n",
    "\n",
    "    all_images, all_labels = load_all_images(class_ids, num_samples)\n",
    "\n",
    "    total_num_images = len(all_images)\n",
    "    print(\"total_num_images:\", total_num_images)\n",
    "    # Shuffle all images before splitting\n",
    "    #all_images2 = np.memmap(all_images, dtype='float32')\n",
    "    perm = np.arange(total_num_images)\n",
    "    np.random.shuffle(perm)\n",
    "    all_images = all_images[perm]\n",
    "    all_labels = all_labels[perm]\n",
    "\n",
    "    validation_size = int(total_num_images * val_fraction)\n",
    "    test_size = int(total_num_images * test_fraction)\n",
    "\n",
    "    validation_images = all_images[:validation_size]\n",
    "    validation_labels = all_labels[:validation_size]\n",
    "\n",
    "    test_images = all_images[validation_size:validation_size + test_size]\n",
    "    test_labels = all_labels[validation_size:validation_size + test_size]\n",
    "\n",
    "    train_images = all_images[validation_size + test_size:]\n",
    "    train_labels = all_labels[validation_size + test_size:]\n",
    "\n",
    "    # Mean normalization\n",
    "    training_mean = np.mean(train_images)\n",
    "    train_images -= training_mean\n",
    "    validation_images -= training_mean\n",
    "    test_images -= training_mean\n",
    "\n",
    "    # Std dev normalization\n",
    "    training_std_dev = np.std(train_images)\n",
    "    train_images /= training_std_dev\n",
    "    validation_images /= training_std_dev\n",
    "    test_images /= training_std_dev\n",
    "\n",
    "    train_dataset = DataSet(train_images, train_labels)\n",
    "    validation_dataset = DataSet(validation_images, validation_labels)\n",
    "    test_dataset = DataSet(test_images, test_labels)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
