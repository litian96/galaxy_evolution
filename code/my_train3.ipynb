{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import StringIO\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import trange\n",
    "from itertools import chain\n",
    "from collections import deque\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "from models3 import *\n",
    "from utils import save_image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next(loader):\n",
    "    return loader.next()[0].data.numpy()\n",
    "\n",
    "def to_nhwc(image, data_format):\n",
    "    if data_format == 'NCHW':\n",
    "        new_image = nchw_to_nhwc(image)\n",
    "    else:\n",
    "        new_image = image\n",
    "    return new_image\n",
    "\n",
    "def to_nchw_numpy(image):\n",
    "    if image.shape[3] in [1, 3]:\n",
    "        new_image = image.transpose([0, 3, 1, 2])\n",
    "    else:\n",
    "        new_image = image\n",
    "    return new_image\n",
    "\n",
    "def norm_img(image, data_format=None):\n",
    "    image = image/127.5 - 1.\n",
    "    if data_format:\n",
    "        image = to_nhwc(image, data_format)\n",
    "    return image\n",
    "\n",
    "def denorm_img(norm, data_format):\n",
    "    return tf.clip_by_value(to_nhwc((norm + 1)*127.5, data_format), 0, 255)\n",
    "\n",
    "def slerp(val, low, high):\n",
    "    \"\"\"Code from https://github.com/soumith/dcgan.torch/issues/14\"\"\"\n",
    "    omega = np.arccos(np.clip(np.dot(low/np.linalg.norm(low), high/np.linalg.norm(high)), -1, 1))\n",
    "    so = np.sin(omega)\n",
    "    if so == 0:\n",
    "        return (1.0-val) * low + val * high # L'Hopital's rule/LERP\n",
    "    return np.sin((1.0-val)*omega) / so * low + np.sin(val*omega) / so * high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(3)\n",
    "class Trainer(object):\n",
    "    def __init__(self, config, data_loader, test_data_loader, generated_data_loader):\n",
    "        self.config = config\n",
    "        self.data_loader = data_loader\n",
    "        self.test_data_loader = test_data_loader\n",
    "        self.generated_data_loader = generated_data_loader\n",
    "        self.dataset = config.dataset\n",
    "\n",
    "        self.beta1 = config.beta1\n",
    "        self.beta2 = config.beta2\n",
    "        self.optimizer = config.optimizer\n",
    "        self.batch_size = config.batch_size\n",
    "\n",
    "        self.step = tf.Variable(0, name='step', trainable=False)\n",
    "        \n",
    "        self.gamma = config.gamma\n",
    "        self.lambda_k = config.lambda_k\n",
    "        \n",
    "        self.ae_lr = tf.placeholder(tf.float32)\n",
    "        self.d_lr = tf.placeholder(tf.float32)\n",
    "        self.reg_lr = tf.placeholder(tf.float32)\n",
    "        self.weight_dis = tf.placeholder(tf.float32)\n",
    "        self.weight_reg = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.z_num = config.z_num\n",
    "        self.conv_hidden_num = config.conv_hidden_num\n",
    "        self.input_scale_size = config.input_scale_size\n",
    "\n",
    "        self.model_dir = config.model_dir\n",
    "        self.load_path = config.load_path\n",
    "\n",
    "        self.use_gpu = config.use_gpu\n",
    "        self.data_format = config.data_format\n",
    "\n",
    "        height = 64\n",
    "        width = 64\n",
    "        self.channel = 3\n",
    "       \n",
    "        self.repeat_num = int(np.log2(height)) - 2\n",
    "\n",
    "        self.start_step = 0\n",
    "        self.log_step = config.log_step\n",
    "        self.max_step = config.max_step\n",
    "        self.save_step = config.save_step\n",
    "        self.lr_update_step = config.lr_update_step\n",
    "\n",
    "        self.is_train = config.is_train\n",
    "        self.build_model()\n",
    "\n",
    "        variables = slim.get_variables_to_restore()\n",
    "        variables_to_restore = [v for v in variables if v.name.split('/')[0]=='AE' or v.name.split('/')[0]=='D']\n",
    "        \n",
    "        self.saver = tf.train.Saver(variables_to_restore)\n",
    "        self.summary_writer = tf.summary.FileWriter(self.model_dir)\n",
    "\n",
    "        sv = tf.train.Supervisor(logdir=self.model_dir,\n",
    "                                is_chief=True,\n",
    "                                saver=self.saver,\n",
    "                                summary_op=None,\n",
    "                                summary_writer=self.summary_writer,\n",
    "                                save_model_secs=1800,\n",
    "                                global_step=self.step,\n",
    "                                ready_for_local_init_op=None)\n",
    "\n",
    "        gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "        sess_config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                                    gpu_options=gpu_options)\n",
    "        self.sess = sv.prepare_or_wait_for_session(config=sess_config)\n",
    "        \n",
    "\n",
    "        if not self.is_train:\n",
    "            # dirty way to bypass graph finilization error\n",
    "            g = tf.get_default_graph()\n",
    "            g._finalized = False\n",
    "            self.build_test_model()\n",
    "       \n",
    "\n",
    "    def build_model(self):\n",
    "        print(\"start to build training model...\")\n",
    "\n",
    "        self.x, self.label = self.data_loader \n",
    "        # self.x: [-1, 3, 64, 64], transpose(self.x): real image\n",
    "        \n",
    "        self.label1 = tf.reshape(self.label,[-1,1])\n",
    "        self.label2 = tf.one_hot(tf.to_int32(self.label), 10)\n",
    "       \n",
    "        x = norm_img(self.x) # x: [-1, 3, 64, 64]\n",
    "        self.pred_label, self.reg_var, self.x_tmp, self.x_tmp2 = reg(x) # this is used for training the regressor, norm image       \n",
    "        d_out, self.D_z, self.AE_var = AE(x, self.label, self.batch_size, self.channel, self.z_num, self.repeat_num,self.conv_hidden_num, self.data_format)        \n",
    "        # d_out: [-1,3,64,64]\n",
    "       \n",
    "        a = 0\n",
    "        a = tf.convert_to_tensor(a, dtype=tf.float32)\n",
    "        \n",
    "        for i in range(10):\n",
    "            changed_label = tf.to_float(tf.convert_to_tensor([i,i,i,i,i,i,i,i,i,i,i,i,i,i,i,i])) # correct\n",
    "           \n",
    "           \n",
    "            d_out_changed, _, self.AE_var2 = AE(x, changed_label, self.batch_size, self.channel, self.z_num, self.repeat_num,self.conv_hidden_num, self.data_format, reuse=True)\n",
    "            #rel = denorm_img(d_out_changed, self.data_format) # the output of the denorm img is good\n",
    "            # correct    \n",
    "            pred_, _, _, _ = reg(d_out_changed, reuse=True)\n",
    "                 \n",
    "            a = tf.add(a, tf.reduce_mean(tf.square(pred_ - tf.to_float(tf.reshape(changed_label, [-1,1])))))\n",
    "         \n",
    "            if i == 0:\n",
    "                self.debug0 = pred_\n",
    "                self.a0 = a\n",
    "            if i == 4:\n",
    "                self.debug4 = pred_\n",
    "                self.a4 = a\n",
    "           \n",
    "            \n",
    "        a = tf.divide(tf.to_float(a), 10) # a is another loss\n",
    "        self.a = a\n",
    "        \n",
    "        AE_x = d_out\n",
    "        self.AE_x = denorm_img(AE_x, self.data_format)\n",
    "     \n",
    "        self.out_label, self.D_var, self.z_vec, self.out_before_softmax = Discriminator(self.D_z, self.batch_size)\n",
    "        self.label_reshaped = tf.reshape(self.out_label,[-1])\n",
    "\n",
    "        # change the label and then run the auto-encoder, and then run the regressor to compute the difference \n",
    "        \n",
    "        \n",
    "        \n",
    "        #---------------------------define the optimizer for 3 components in this network-----------------------##\n",
    "        optimizer = tf.train.AdamOptimizer\n",
    "       \n",
    "        ae_optimizer = optimizer(self.ae_lr)\n",
    "        d_optimizer = optimizer(self.d_lr)\n",
    "        reg_optimizer = optimizer(self.reg_lr)\n",
    "\n",
    "        ##...........................Define the loss function here.May be changed................................##\n",
    "        self.ae_loss = tf.reduce_mean(tf.square(AE_x-x)) + self.weight_dis* tf.reduce_mean(tf.reduce_sum(self.label2 * tf.log(self.out_label+1e-8), 1)) + self.weight_reg * self.a\n",
    "        \n",
    "        print(\"size of ae loss\")\n",
    "        print(self.ae_loss.get_shape())\n",
    "        self.ae_optim = ae_optimizer.minimize(self.ae_loss, var_list=self.AE_var)\n",
    "    \n",
    "        self.d_loss = -tf.reduce_mean(tf.reduce_sum(self.label2 * tf.log(self.out_label+1e-8), 1))\n",
    "        self.d_optim = d_optimizer.minimize(self.d_loss, var_list=self.D_var)\n",
    "        # label2 is the real label, out_label is the predicted label\n",
    "        \n",
    "        self.d_loss2 = tf.reduce_sum(self.label2 * tf.log(self.out_label+1e-8), 1)\n",
    "        \n",
    "       \n",
    "        self.reg_loss = tf.reduce_mean(tf.square(self.pred_label-self.label1)) # not sure here is self.label or self.label1\n",
    "        self.reg_optim = reg_optimizer.minimize(self.reg_loss, var_list = self.reg_var)\n",
    "    \n",
    "        \n",
    "    def build_test_model(self):\n",
    "        with tf.variable_scope(\"test\") as vs:\n",
    "            # Extra ops for interpolation\n",
    "            z_optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "            self.z_r = tf.get_variable(\"z_r\", [self.batch_size, self.z_num], tf.float32)\n",
    "\n",
    "        test_variables = tf.contrib.framework.get_variables(vs)\n",
    "        self.sess.run(tf.variables_initializer(test_variables))\n",
    "\n",
    "\n",
    "    def autoencode(self, inputs, label, path, idx=None):\n",
    "        img = inputs\n",
    "        if img.shape[3] in [1, 3]:\n",
    "            img = img.transpose([0, 3, 1, 2])\n",
    "\n",
    "            #x_path = os.path.join('./aaa.jpg')\n",
    "        x = self.sess.run(self.AE_x, {self.x: img, self.label: label})\n",
    "        save_image(x, \"aaa.jpg\")\n",
    "        print(\"[*] Samples saved\")\n",
    "        return x\n",
    "    \n",
    "    def Do_reg(self, inputs):\n",
    "        \n",
    "        if inputs.shape[3] in [1, 3]:\n",
    "            inputs = inputs.transpose([0, 3, 1, 2])\n",
    "        return self.sess.run(self.pred_label, {self.x: inputs})\n",
    "\n",
    "    def encode(self, inputs):\n",
    "        if inputs.shape[3] in [1, 3]:\n",
    "            inputs = inputs.transpose([0, 3, 1, 2])\n",
    "        return self.sess.run(self.D_z, {self.x: inputs})\n",
    "\n",
    "    def decode(self, z, label):\n",
    "        return self.sess.run(self.AE_x, {self.D_z: z, self.label: label})\n",
    "\n",
    "    def interpolate_D(self, real1_batch, real2_batch, label1, label2, step=0, root_path=\".\"):\n",
    "\n",
    "        real1_encode = self.encode(real1_batch) #(16,512,2,2)\n",
    "        real2_encode = self.encode(real2_batch) # (16,512,2,2)\n",
    "\n",
    "        decodes = []\n",
    "        changed_label = [0,1,2,3,4,5,6,7,8,9]\n",
    "       \n",
    "    \n",
    "       \n",
    "        for i in range(10):\n",
    "            z_decode = self.decode(real1_encode, np.repeat(changed_label[i],16))\n",
    "            decodes.append(z_decode)\n",
    "\n",
    "        decodes = np.stack(decodes).transpose([1, 0, 2, 3, 4])\n",
    "        for idx, img in enumerate(decodes):\n",
    "            img = np.concatenate([[real1_batch[idx]], img, [real2_batch[idx]]], 0)\n",
    "            save_image(img, \"./interpolation\"+str(idx)+\".png\", nrow=10 + 2)\n",
    "        for idx in range(16):\n",
    "            im = Image.open(\"./interpolation\"+str(idx)+\".png\")\n",
    "            draw = ImageDraw.Draw(im)\n",
    "            label = label1[idx]\n",
    "            draw.rectangle((label * 64,0, (label+1)*64, 64), fill=None, outline=\"red\")\n",
    "            im.save(\"./interpolation\"+str(idx)+\".png\")\n",
    "\n",
    "    def change_attributes(self, real_batch, root_path='.'):\n",
    "\n",
    "        real_encode = self.encode(real_batch)\n",
    "        decodes = []\n",
    "        imgs = []\n",
    "        # test batch size\n",
    "        test_sample = random.sample([0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9], 16)\n",
    "        decodes=self.decode(real_encode,test_sample)\n",
    "        \n",
    "        save_image(decodes, os.path.join(\"./\", \"test_changed_attri.png\"))\n",
    "        \n",
    "        decodes =self.decode(real_encode,[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "        save_image(decodes, os.path.join(\"./\", \"test_changed_attri_0.png\"))\n",
    "\n",
    "    def test(self):\n",
    "        root_path = \"./\"\n",
    "        for step in range(3):\n",
    "            real1_batch, label1_batch = self.get_image_from_loader()         \n",
    "            save_image(real1_batch, os.path.join(root_path, 'test{}_real1.png'.format(step)))\n",
    "            self.autoencode(real1_batch, label1_batch, self.model_dir, idx=os.path.join(root_path, \"test{}_real1\".format(step)))\n",
    "            self.change_attributes(real1_batch, self.model_dir)\n",
    "            \n",
    "    def get_image_from_loader(self):\n",
    "        tmp, label = self.data_loader\n",
    "        print(tmp.get_shape())\n",
    "        x, label2 = self.sess.run([tmp,label])\n",
    "        if self.data_format == 'NCHW':\n",
    "            x = x.transpose([0, 2, 3, 1])\n",
    "            print(x)\n",
    "        return x, label2\n",
    "    \n",
    "    def get_test_image_from_loader(self):\n",
    "        tmp, label = self.test_data_loader\n",
    "        x, label2 = self.sess.run([tmp,label])\n",
    "        if self.data_format == 'NCHW':\n",
    "            x = x.transpose([0, 2, 3, 1])\n",
    "        return x, label2\n",
    "    \n",
    "    def get_generated_image_from_loader(self):\n",
    "        tmp, label = self.generated_data_loader\n",
    "        x, label2 = self.sess.run([tmp,label])\n",
    "        if self.data_format == 'NCHW':\n",
    "            x = x.transpose([0, 2, 3, 1])\n",
    "        return x, label2\n",
    "\n",
    "    def train_reg(self, reglr, step):\n",
    "        for i in trange(0, step):\n",
    "            self.sess.run(self.reg_optim, feed_dict={self.weight_dis:0.0, self.ae_lr: 0.0, self.d_lr: 0.0, self.reg_lr: reglr, self.weight_reg:0.0})\n",
    "            Reg_loss, pred_label_, real_label_  = self.sess.run([self.reg_loss, self.pred_label, self.label], feed_dict={self.weight_dis:0.0, self.ae_lr: 0.0, self.d_lr: 0.0, self.reg_lr: reglr, self.weight_reg: 0.0})\n",
    "            if i % 5 == 0:\n",
    "                print(\"[train regressor] step \"+str(i)+\", mse loss for regression is: \"+str(Reg_loss))\n",
    "                print(\"pred label:\")\n",
    "                print(pred_label_)\n",
    "                print(\"real_label:\")\n",
    "                print(real_label_)\n",
    "                \n",
    "    \n",
    "    def train_AE(self, aelr, dlr, step):\n",
    "        for step in trange(0, step):                \n",
    "            self.sess.run(self.ae_optim, feed_dict={self.weight_dis: 0.0, self.ae_lr: aelr, self.d_lr: dlr, self.weight_reg: 0})\n",
    "            AE_loss, D_loss, D_loss2, D_out, real_label, real_label_one_hot, zz, before = self.sess.run([self.ae_loss,self.d_loss,self.d_loss2, self.out_label, self.label, self.label2, self.z_vec, self.out_before_softmax], feed_dict={self.weight_dis: 0.0, self.ae_lr: aelr, self.d_lr: dlr, self.weight_reg:0.0}) \n",
    "               \n",
    "            if step % 25 == 0:                \n",
    "                print(\"D out after softmax is:\")\n",
    "                print(D_out)                   \n",
    "                print(\"[train AE] step: \"+str(step)+\", ae_loss: \"+str(AE_loss)+\", d_loss = \" + str(D_loss)+\"\\n\")\n",
    "\n",
    "    def train_D(self, aelr, dlr):\n",
    "        for step in trange(5000, 10000):\n",
    "            self.sess.run(self.d_optim, feed_dict={self.weight_dis: 0.0, self.ae_lr: aelr, self.d_lr: dlr, self.weight_reg:0.0})\n",
    "            D_loss, D_loss2, D_out, real_label, real_label_one_hot = self.sess.run([self.d_loss, self.d_loss2, self.out_label, self.label, self.label2], feed_dict={self.weight_dis: 0.0, self.ae_lr: aelr, self.d_lr: dlr, self.weight_reg:0.0}) \n",
    "            AE_loss = self.sess.run(self.ae_loss, feed_dict={self.weight_dis: 0.0, self.ae_lr: aelr, self.d_lr: dlr, self.weight_reg:0.0})\n",
    "            if step % 25 == 0:    \n",
    "                print(\"the output of dis (after softmax):\")\n",
    "                print(D_out)      \n",
    "                print(\"[train D] step: \"+str(step)+\", ae_loss: \"+str(AE_loss)+\", d_loss = \" + str(D_loss)+\"\\n\")\n",
    "            \n",
    "    def train_both(self, weightdis, weightreg, aelr, dlr, step):\n",
    "        for step in trange(0, step):\n",
    "            \n",
    "            self.sess.run([self.ae_optim, self.d_optim], feed_dict={self.weight_dis: weightdis, self.ae_lr: aelr, self.d_lr: dlr, self.weight_reg: weightreg})\n",
    "            #D_loss = self.sess.run(self.d_loss,feed_dict={self.weight_: weight})\n",
    "            \n",
    "            a_0, a_4, pred_0,pred_4, reg_loss_on_gen,D_loss,D_loss2, AE_loss,D_out, real_label, real_label_one_hot, zz, before = self.sess.run([self.a0, self.a4, self.debug0, self.debug4, self.a, self.d_loss, self.d_loss2, self.ae_loss, self.out_label, self.label, self.label2, self.z_vec, self.out_before_softmax], feed_dict={self.weight_dis: weightdis, self.ae_lr: aelr, self.d_lr: dlr, self.weight_reg: weightreg}) \n",
    "            \n",
    "            if step % 25 == 0:  \n",
    "                print(\"the output of dis (after softmax):\")\n",
    "                print(D_out)\n",
    "\n",
    "                print(\"[train together]: step: \"+str(step)+\", ae_loss: \"+str(AE_loss)+\", d_loss = \" + str(D_loss)+\"\\n\")\n",
    "            print(\"regression loss on transformed images is: \" + str(reg_loss_on_gen))\n",
    "            print(\"the prediction value for transformed image with conditioned label 0 is:\")\n",
    "            print(pred_0)\n",
    "            print(a_0)\n",
    "           \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#from trainer import Trainer\n",
    "from config import get_config\n",
    "from data_loader import get_loader\n",
    "from data_loader import get_loader_test\n",
    "from data_loader import get_loader_generated\n",
    "from utils import prepare_dirs_and_logger, save_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(3)\n",
    "config, unparsed = get_config()\n",
    "prepare_dirs_and_logger(config)\n",
    "\n",
    "rng = np.random.RandomState(config.random_seed)\n",
    "tf.set_random_seed(config.random_seed)\n",
    "\n",
    "if config.is_train:\n",
    "    data_path = config.data_path\n",
    "    batch_size = config.batch_size\n",
    "    do_shuffle = False\n",
    "else:\n",
    "    setattr(config, 'batch_size', 16)\n",
    "    if config.test_data_path is None:\n",
    "        data_path = config.data_path\n",
    "    else:\n",
    "        data_path = config.test_data_path\n",
    "    batch_size = config.sample_per_image\n",
    "    do_shuffle = False\n",
    "\n",
    "data_loader = get_loader(\n",
    "            data_path, config.batch_size, config.input_scale_size,\n",
    "            config.data_format, config.split)\n",
    "test_data_loader = get_loader_test(\n",
    "            data_path, config.batch_size, config.input_scale_size,\n",
    "            config.data_format, config.split)\n",
    "generated_data_loader = get_loader_generated(data_path, config.batch_size, config.input_scale_size,\n",
    "            config.data_format, config.split)\n",
    "print(\"has loaded data....\")\n",
    "trainer = Trainer(config, data_loader, test_data_loader, generated_data_loader)\n",
    "print(\"has initialized trainer...\")\n",
    "\n",
    "save_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()\n",
    "g._finalized = False\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "trainer.sess.run(init)\n",
    "chkpt_fname = tf.train.latest_checkpoint(\"./logs/dis\")\n",
    "trainer.saver.restore(trainer.sess, chkpt_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x, _ = trainer.data_loader\n",
    "#x = norm_img(x)\n",
    "#d_out_changed,_,_ = AE(x, tf.to_float([9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9]), trainer.batch_size, trainer.channel, trainer.z_num, trainer.repeat_num, trainer.conv_hidden_num, trainer.data_format, reuse=True)\n",
    "#rel = denorm_img(d_out_changed, trainer.data_format) # the output of the denorm img is good\n",
    "\n",
    "\n",
    "loss, x0, x4, a_0, a_4, pred_0, pred_4,reg_loss_on_gen = trainer.sess.run([trainer.a, trainer.x0, trainer.x4, trainer.a0, trainer.a4, trainer.debug0, trainer.debug4, trainer.a], feed_dict={trainer.weight_dis: 0, trainer.ae_lr: 0, trainer.d_lr: 0, trainer.weight_reg:0})\n",
    "#print(pred_0)\n",
    "#print(pred_1)\n",
    "#print(pred_2)\n",
    "#print(pred_3)\n",
    "#print(pred_4)\n",
    "#print(pred_8)\n",
    "#print(pred_9)\n",
    "#print(\"mse loss: \"+str(loss))\n",
    "save_image(x0,'./img0.jpg')\n",
    "save_image(x4,'./img4.jpg')\n",
    "\n",
    "\n",
    "inputs = x4\n",
    "#print(inputs.shape)  #(16,64,64,3)\n",
    "\n",
    "if inputs.shape[3] in [1, 3]:\n",
    "        inputs = inputs.transpose([0, 3, 1, 2])\n",
    "pred_wrong =  trainer.sess.run(trainer.debug4, {trainer.gen: inputs})\n",
    "print(pred_wrong)\n",
    "t1, t_ae2 = trainer.sess.run([trainer.var2, trainer.AE_var2], {trainer.gen:inputs})\n",
    "#\n",
    "print(\"--------------\")\n",
    "print(\"number of variables in reused reg: \" + str(len(t1)))\n",
    "print(\"------------\")\n",
    "print(\"number of variables in reused AE: \" + str(len(t_ae2)))\n",
    "pred_right = trainer.sess.run(trainer.pred_label, {trainer.x: inputs})\n",
    "print(pred_right)\n",
    "print(\"--------------\")\n",
    "print(\"--------------\")\n",
    "t2, t_ae = trainer.sess.run([trainer.reg_var, trainer.AE_var], {trainer.x: inputs})\n",
    "print(\"in original reg model there are :\" + str(len(t2)) +\" set variables.\")\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "print(\"in original AE model there are :\" + str(len(t_ae)) +\" set variables.\")\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "x0 = Image(filename='./img0.jpg')\n",
    "x4 = Image(filename='./img4.jpg')\n",
    "\n",
    "display(x0, x4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "real_batch, label_batch = trainer.get_test_image_from_loader()\n",
    "trainer.autoencode(real_batch, [0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], None)\n",
    "\n",
    "x = Image(filename='./aaa.jpg')  \n",
    "display(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_reg(0.00005, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "tot = 0\n",
    "test_real_label = np.zeros((100 * 16, 1))\n",
    "test_pred_label = np.zeros((100 * 16, 1))\n",
    "\n",
    "for i in range(100):\n",
    "    real_batch, label_batch = trainer.get_image_from_loader()\n",
    "    print(real_batch.shape[3])\n",
    "    test_pred = trainer.Do_reg(real_batch)\n",
    "    test_real = np.reshape(label_batch,(-1,1))\n",
    "    test_real_label[i * 16: (i + 1) * 16] = test_real\n",
    "    test_pred_label[i * 16: (i + 1) * 16] = test_pred\n",
    "    #loss = (test_pred - test_real)**2 * 1.0 / 16\n",
    "    loss = mean_squared_error(test_pred, test_real)\n",
    "    tot += loss\n",
    "    #print(\"testing mse loss is: \"+str(loss))\n",
    "print(\"mse loss is: \" + str(tot / 100))\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(test_pred_label, test_real_label, marker='x', s = 2)\n",
    "plt.xlim(-4, 12)\n",
    "ax.set_xlabel('regression value')\n",
    "ax.set_ylabel('real label')\n",
    "ax.set_title(\"predicted BTDR value distribution for real galaxies on testing set\")\n",
    "plt.plot([0,9], [0,9],'k-')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.set_xticks([-4, -3, -2, -1,0, 1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "ax.set_yticks([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_AE(0.00004,0.00004, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_AE(0.00004,0.00004, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"a\")\n",
    "real_batch, label_batch = trainer.get_test_image_from_loader()\n",
    "trainer.autoencode(real_batch, label_batch, trainer.model_dir, idx=os.path.join(\"./\", \"recovered\"))\n",
    "im = Image.open('./recovered_real.png', 'r')\n",
    "#imshow(np.asarray(im))\n",
    "print(label_batch)\n",
    "\n",
    "save_image(real_batch, os.path.join(\"./\", 'original.png'))\n",
    "im_real = Image.open('./original.png','r')\n",
    "#imshow(np.asarray(im))\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "x = Image(filename='./recovered_real.png') \n",
    "y = Image(filename='./original.png') \n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_AE(0.00004,0.00004, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"a\")\n",
    "real_batch, label_batch = trainer.get_test_image_from_loader()\n",
    "trainer.autoencode(real_batch, label_batch, trainer.model_dir, idx=os.path.join(\"./\", \"recovered\"))\n",
    "im = Image.open('./recovered_real.png', 'r')\n",
    "#imshow(np.asarray(im))\n",
    "print(label_batch)\n",
    "\n",
    "save_image(real_batch, os.path.join(\"./\", 'original.png'))\n",
    "im_real = Image.open('./original.png','r')\n",
    "#imshow(np.asarray(im))\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "x = Image(filename='./recovered_real.png') \n",
    "y = Image(filename='./original.png') \n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_AE(0.00004,0.00004, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"a\")\n",
    "real_batch, label_batch = trainer.get_test_image_from_loader()\n",
    "trainer.autoencode(real_batch, label_batch, trainer.model_dir, idx=os.path.join(\"./\", \"recovered\"))\n",
    "im = Image.open('./recovered_real.png', 'r')\n",
    "#imshow(np.asarray(im))\n",
    "print(label_batch)\n",
    "\n",
    "save_image(real_batch, os.path.join(\"./\", 'original.png'))\n",
    "im_real = Image.open('./original.png','r')\n",
    "#imshow(np.asarray(im))\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "x = Image(filename='./recovered_real.png') \n",
    "y = Image(filename='./original.png') \n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.train_AE(0.00004,0.00004, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"a\")\n",
    "real_batch, label_batch = trainer.get_test_image_from_loader()\n",
    "trainer.autoencode(real_batch, label_batch, trainer.model_dir, idx=os.path.join(\"./\", \"recovered\"))\n",
    "#im = Image.open('./recovered_real.png', 'r')\n",
    "#imshow(np.asarray(im))\n",
    "print(label_batch)\n",
    "\n",
    "save_image(real_batch, os.path.join(\"./\", 'original.png'))\n",
    "im_real = Image.open('./original.png','r')\n",
    "#imshow(np.asarray(im))\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "#x = Image(filename='./recovered_real.png') \n",
    "y = Image(filename='./original.png') \n",
    "display( y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.saver.save(trainer.sess,'ae_loss=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_AE(0.00004,0.00004, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"a\")\n",
    "real_batch, label_batch = trainer.get_test_image_from_loader()\n",
    "trainer.autoencode(real_batch, label_batch, trainer.model_dir, idx=os.path.join(\"./\", \"recovered\"))\n",
    "im = Image.open('./recovered_real.png', 'r')\n",
    "#imshow(np.asarray(im))\n",
    "print(label_batch)\n",
    "\n",
    "save_image(real_batch, os.path.join(\"./\", 'original.png'))\n",
    "im_real = Image.open('./original.png','r')\n",
    "#imshow(np.asarray(im))\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "x = Image(filename='./recovered_real.png') \n",
    "y = Image(filename='./original.png') \n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.saver.save(trainer.sess,'ae_loss=0.0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_D(0.00008,0.00008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.saver.save(trainer.sess,'after_dis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.train_D(0.00008,0.00008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.003,0.0000001,0.00002,0.00008, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.saver.save(trainer.sess,'a_little')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.0035,0.00001,0.00002,0.00008, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.0035,0.00002,0.00002,0.00008, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.saver.save(trainer.sess,'try1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.0035,0.0002,0.00002,0.00008, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.0035,0.0004,0.00002,0.00008, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.0035,0.00005,0.00002,0.00008, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.0015,0.0001,0.00004,0.00008, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.002,0.0,0.00004,0.00008, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.0025,0.0,0.00004,0.00008, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.003,0.0,0.00004,0.00008, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pp = PdfPages('evaluation.pdf')\n",
    "\n",
    "tot = 0\n",
    "fake_label = np.zeros((100 * 16, 1))\n",
    "fake_pred_label = np.zeros((100 * 16, 1))\n",
    "for i in range(100):\n",
    "    fake_batch, label = trainer.get_generated_image_from_loader()\n",
    "    fake_pred = trainer.Do_reg(fake_batch)\n",
    "    label = np.reshape(label,(-1,1))\n",
    "    fake_label[i * 16: (i + 1) * 16] = label\n",
    "    fake_pred_label[i * 16: (i + 1) * 16] = fake_pred\n",
    "    #loss = (test_pred - test_real)**2 * 1.0 / 16\n",
    "    loss = mean_squared_error(label, fake_pred)\n",
    "    tot += loss\n",
    "    if i == 0:\n",
    "        print(label[0:16])\n",
    "        print(fake_pred[0:16])\n",
    "        save_image(fake_batch, os.path.join(\"./\", 'generated.png'))\n",
    "        \n",
    "mse = tot / 100\n",
    "    #print(\"testing mse loss is: \"+str(loss))\n",
    "print(\"mse loss is: \" + str(mse))\n",
    "x = Image(filename='./generated.png')\n",
    "display(x)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fake_pred_label, fake_label, marker='x', s = 2)\n",
    "plt.xlim(-4, 12)\n",
    "ax.set_xlabel('regression value')\n",
    "ax.set_ylabel('real label')\n",
    "ax.set_title(\"predicted BTDR value distribution for generated galaxies from testing set\")\n",
    "plt.plot([0,9], [0,9],'k-')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.text(5, 1, r'mse = ' + str(mse), fontsize=15)\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.set_xticks([-4, -3, -2, -1,0, 1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "ax.set_yticks([0,1,2,3,4,5,6,7,8,9])\n",
    "pp.savefig(fig)\n",
    "\n",
    "#---------\n",
    "\n",
    "tot = 0\n",
    "fake_label = np.zeros((100 * 16, 1))\n",
    "fake_pred_label = np.zeros((100 * 16, 1))\n",
    "for i in range(100):\n",
    "    fake_batch, label = trainer.get_image_from_loader()\n",
    "    fake_pred = trainer.Do_reg(fake_batch)\n",
    "    label = np.reshape(label,(-1,1))\n",
    "    fake_label[i * 16: (i + 1) * 16] = label\n",
    "    fake_pred_label[i * 16: (i + 1) * 16] = fake_pred\n",
    "    #loss = (test_pred - test_real)**2 * 1.0 / 16\n",
    "    loss = mean_squared_error(label, fake_pred)\n",
    "    tot += loss\n",
    "    if i == 0:\n",
    "        print(label[0:16])\n",
    "        print(fake_pred[0:16])\n",
    "        save_image(fake_batch, os.path.join(\"./\", 'generated.png'))\n",
    "        \n",
    "mse = tot / 100\n",
    "    #print(\"testing mse loss is: \"+str(loss))\n",
    "print(\"mse loss is: \" + str(mse))\n",
    "x = Image(filename='./generated.png')\n",
    "display(x)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fake_pred_label, fake_label, marker='x', s = 2)\n",
    "plt.xlim(-4, 12)\n",
    "ax.set_xlabel('regression value')\n",
    "ax.set_ylabel('real label')\n",
    "ax.set_title(\"predicted BTDR value distribution for real galaxies on training set\")\n",
    "plt.plot([0,9], [0,9],'k-')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.text(5, 1, r'mse = ' + str(mse), fontsize=15)\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.set_xticks([-4, -3, -2, -1,0, 1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "ax.set_yticks([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "pp.savefig(fig)\n",
    "#----------------------\n",
    "\n",
    "tot = 0\n",
    "fake_label = np.zeros((100 * 16, 1))\n",
    "fake_pred_label = np.zeros((100 * 16, 1))\n",
    "for i in range(100):\n",
    "    fake_batch, label = trainer.get_test_image_from_loader()\n",
    "    fake_pred = trainer.Do_reg(fake_batch)\n",
    "    label = np.reshape(label,(-1,1))\n",
    "    fake_label[i * 16: (i + 1) * 16] = label\n",
    "    fake_pred_label[i * 16: (i + 1) * 16] = fake_pred\n",
    "    #loss = (test_pred - test_real)**2 * 1.0 / 16\n",
    "    loss = mean_squared_error(label, fake_pred)\n",
    "    tot += loss\n",
    "    if i == 0:\n",
    "        print(label[0:16])\n",
    "        print(fake_pred[0:16])\n",
    "        save_image(fake_batch, os.path.join(\"./\", 'generated.png'))\n",
    "        \n",
    "mse = tot / 100\n",
    "    #print(\"testing mse loss is: \"+str(loss))\n",
    "print(\"mse loss is: \" + str(mse))\n",
    "x = Image(filename='./generated.png')\n",
    "display(x)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fake_pred_label, fake_label, marker='x', s = 2)\n",
    "plt.xlim(-4, 12)\n",
    "ax.set_xlabel('regression value')\n",
    "ax.set_ylabel('real label')\n",
    "ax.set_title(\"predicted BTDR value distribution for real galaxies on testing set\")\n",
    "plt.plot([0,9], [0,9],'k-')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.text(5, 1, r'mse = ' + str(mse), fontsize=15)\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.set_xticks([-4, -3, -2, -1,0, 1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "ax.set_yticks([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "pp.savefig(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# now, begin to test\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "real_batch, label_batch = trainer.get_test_image_from_loader()\n",
    "real1_encode = trainer.encode(real_batch) #(16,512,2,2)\n",
    "       \n",
    "\n",
    "decodes=[]\n",
    "changed_label = [0,1,2,3,4,5,6,7,8,9]\n",
    "       \n",
    "    \n",
    "for i in range(10):\n",
    "    z_decode = trainer.decode(real1_encode, np.repeat(changed_label[i],16))\n",
    "    decodes.append(z_decode)\n",
    "\n",
    "decodes = np.stack(decodes).transpose([1, 0, 2, 3, 4])\n",
    "for idx, img in enumerate(decodes):\n",
    "    img = np.concatenate([[real_batch[idx]], img], 0)\n",
    "    save_image(img, \"./interpolation\"+str(idx)+\".png\", nrow=10 + 1)\n",
    "for idx in range(16):\n",
    "    im = Image.open(\"./interpolation\"+str(idx)+\".png\")\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    label = label_batch[idx]\n",
    "    draw.rectangle(((label+1) * 66,0, (label+2)*66, 68), fill=None, outline=\"red\")\n",
    "    im.save(\"./interpolation\"+str(idx)+\".png\")\n",
    "    \n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "#x = Image(filename='./original.png') \n",
    "#y = Image(filename='./recovered_real.png') \n",
    "t0 = Image(filename='./interpolation0.png')\n",
    "t1 = Image(filename='./interpolation1.png')\n",
    "t2 = Image(filename='./interpolation2.png')\n",
    "t3 = Image(filename='./interpolation3.png')\n",
    "t4 = Image(filename='./interpolation4.png')\n",
    "t5 = Image(filename='./interpolation5.png')\n",
    "t6 = Image(filename='./interpolation6.png')\n",
    "t7 = Image(filename='./interpolation7.png')\n",
    "t8 = Image(filename='./interpolation8.png')\n",
    "t9 = Image(filename='./interpolation9.png')\n",
    "t10 = Image(filename='./interpolation10.png')\n",
    "t11 = Image(filename='./interpolation11.png')\n",
    "t12 = Image(filename='./interpolation12.png')\n",
    "t13 = Image(filename='./interpolation13.png')\n",
    "t14 = Image(filename='./interpolation14.png')\n",
    "t15 = Image(filename='./interpolation15.png')\n",
    "display(t0, t1,t2,t3,t4,t5,t6,t7,t8,t9,t10,t11,t12,t13,t14,t15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_both(0.003, 0.00008, 0.00008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(50):\n",
    "    real_batch, label_batch = trainer.get_test_image_from_loader()\n",
    "    real_encode = trainer.encode(real_batch)\n",
    "    \n",
    "    print(\"encoding has finished\")\n",
    "  \n",
    "    test_sample = random.sample([0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9], 16)\n",
    "    decodes=trainer.decode(real_encode,test_sample)\n",
    "    \n",
    "    print(\"decoding has finished\")\n",
    "    \n",
    "    j = 0\n",
    "    for k in test_sample:\n",
    "        im = Image.fromarray(decodes[j].astype(np.uint8))\n",
    "        im.save(\"/mnt/ds3lab/litian/AE_BEGAN/data/galaxy_64_bdtr/generated2/\"+str(k)+\"/\"+str(i)+\"_\"+str(j)+\".jpg\")\n",
    "        print(\"have saved the iamge in:\"+\"/mnt/ds3lab/litian/AE_BEGAN/data/galaxy_64_bdtr/generated2/\"+str(k)+\"/\"+str(i)+\"_\"+str(j)+\".jpg\")\n",
    "        j = j + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.saver.save(trainer.sess,'try4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
